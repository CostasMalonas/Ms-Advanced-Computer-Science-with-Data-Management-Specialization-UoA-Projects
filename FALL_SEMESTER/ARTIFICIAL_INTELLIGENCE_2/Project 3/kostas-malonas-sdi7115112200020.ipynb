{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-09T11:36:29.544825Z","iopub.status.busy":"2024-02-09T11:36:29.544519Z","iopub.status.idle":"2024-02-09T11:36:53.518537Z","shell.execute_reply":"2024-02-09T11:36:53.517552Z","shell.execute_reply.started":"2024-02-09T11:36:29.544797Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import re\n","import json\n","import spacy\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from wordcloud import WordCloud\n","from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score, confusion_matrix\n","import random\n","random.seed(0)\n","import numpy as np\n","np.random.seed(0)\n","from sklearn.model_selection import train_test_split,StratifiedKFold\n","import itertools\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","import gensim\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","import torch\n","torch.manual_seed(0)\n","import torch.nn as nn\n","from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","import nltk\n","from gensim.models.phrases import Phrases, Phraser\n","nltk.download('punkt')\n","from torch.utils.data import TensorDataset, DataLoader\n","import optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T11:08:04.198990Z","iopub.status.busy":"2024-01-04T11:08:04.197975Z","iopub.status.idle":"2024-01-04T11:08:18.492307Z","shell.execute_reply":"2024-01-04T11:08:18.491179Z","shell.execute_reply.started":"2024-01-04T11:08:04.198949Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install torchtext"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:36:53.521310Z","iopub.status.busy":"2024-02-09T11:36:53.520577Z","iopub.status.idle":"2024-02-09T11:36:54.627400Z","shell.execute_reply":"2024-02-09T11:36:54.626451Z","shell.execute_reply.started":"2024-02-09T11:36:53.521274Z"},"trusted":true},"outputs":[],"source":["import torchtext\n","from torchtext import data\n","from torchtext.data import get_tokenizer #https://stackoverflow.com/questions/42711144/how-can-i-install-torchtext"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Load our data</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:36:54.629510Z","iopub.status.busy":"2024-02-09T11:36:54.628789Z","iopub.status.idle":"2024-02-09T11:36:55.159000Z","shell.execute_reply":"2024-02-09T11:36:55.158000Z","shell.execute_reply.started":"2024-02-09T11:36:54.629475Z"},"trusted":true},"outputs":[],"source":["df_train_set = pd.read_csv('/kaggle/input/ys19-2023-assignment-3/train_set.csv')\n","df_test_set = pd.read_csv('/kaggle/input/ys19-2023-assignment-3/test_set.csv')\n","df_valid_set = pd.read_csv('/kaggle/input/ys19-2023-assignment-3/valid_set.csv')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>We print our data and check for null values</h1><br>\n","\n","We can observe from the output of the **info** method that there are no null values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T07:55:40.598595Z","iopub.status.busy":"2024-01-30T07:55:40.598235Z","iopub.status.idle":"2024-01-30T07:55:40.637234Z","shell.execute_reply":"2024-01-30T07:55:40.636261Z","shell.execute_reply.started":"2024-01-30T07:55:40.598568Z"},"trusted":true},"outputs":[],"source":["print(df_train_set.head(),'\\n')\n","print(df_train_set.info(), '\\n')\n","\n","print(df_valid_set.head(),'\\n')\n","print(df_valid_set.info(), '\\n')\n","\n","print(df_test_set.head(),'\\n')\n","print(df_test_set.info(), '\\n')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Barplots that illustrate the number of tweets and their sentiment for each party</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:56:07.217995Z","iopub.status.busy":"2024-01-03T18:56:07.217551Z","iopub.status.idle":"2024-01-03T18:56:07.243131Z","shell.execute_reply":"2024-01-03T18:56:07.242188Z","shell.execute_reply.started":"2024-01-03T18:56:07.217946Z"},"trusted":true},"outputs":[],"source":["group_df_by_sentiment_party_train = df_train_set.groupby(['Sentiment', 'Party']).size().reset_index(name='NumOfTweets')\n","group_df_by_sentiment_party_valid = df_valid_set.groupby(['Sentiment', 'Party']).size().reset_index(name='NumOfTweets')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:56:16.566210Z","iopub.status.busy":"2024-01-03T18:56:16.565787Z","iopub.status.idle":"2024-01-03T18:56:17.076244Z","shell.execute_reply":"2024-01-03T18:56:17.075061Z","shell.execute_reply.started":"2024-01-03T18:56:16.566176Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,8))\n","sns.barplot(x='Party', y='NumOfTweets', hue='Sentiment', data=group_df_by_sentiment_party_train)\n","plt.title('Number of Tweets/Sentiment per Party for Train set')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:56:53.274916Z","iopub.status.busy":"2024-01-03T18:56:53.274231Z","iopub.status.idle":"2024-01-03T18:56:53.744101Z","shell.execute_reply":"2024-01-03T18:56:53.742968Z","shell.execute_reply.started":"2024-01-03T18:56:53.274866Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,8))\n","sns.barplot(x='Party', y='NumOfTweets', hue='Sentiment', data=group_df_by_sentiment_party_valid)\n","plt.title('Number of Tweets/Sentiment per Party for Valid set')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Plot the number of tweets for each party</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:57:16.717041Z","iopub.status.busy":"2024-01-03T18:57:16.715901Z","iopub.status.idle":"2024-01-03T18:57:17.088864Z","shell.execute_reply":"2024-01-03T18:57:17.087717Z","shell.execute_reply.started":"2024-01-03T18:57:16.716996Z"},"trusted":true},"outputs":[],"source":["df_train_set['Party'].value_counts().plot(kind='bar', figsize=(12,8))\n","plt.title('Number of Tweets/Party for Train set')\n","plt.ylabel('Num of Tweets')\n","plt.xlabel('Party')\n","plt.xticks(rotation=45)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:57:25.861446Z","iopub.status.busy":"2024-01-03T18:57:25.861040Z","iopub.status.idle":"2024-01-03T18:57:26.220279Z","shell.execute_reply":"2024-01-03T18:57:26.219051Z","shell.execute_reply.started":"2024-01-03T18:57:25.861412Z"},"trusted":true},"outputs":[],"source":["df_valid_set['Party'].value_counts().plot(kind='bar', figsize=(12,8))\n","plt.title('Number of Tweets/Party for Validation set')\n","plt.ylabel('Num of Tweets')\n","plt.xlabel('Party')\n","plt.xticks(rotation=45)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:57:34.265963Z","iopub.status.busy":"2024-01-03T18:57:34.265566Z","iopub.status.idle":"2024-01-03T18:57:34.606091Z","shell.execute_reply":"2024-01-03T18:57:34.604956Z","shell.execute_reply.started":"2024-01-03T18:57:34.265930Z"},"trusted":true},"outputs":[],"source":["df_test_set['Party'].value_counts().plot(kind='bar', figsize=(12,8))\n","plt.title('Number of Tweets/Party for Test set')\n","plt.ylabel('Num of Tweets')\n","plt.xlabel('Party')\n","plt.xticks(rotation=45)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Data preprocessing</h1>\n","<h4>Turn the categorical values to numerical</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:58:01.722801Z","iopub.status.busy":"2024-01-03T18:58:01.722378Z","iopub.status.idle":"2024-01-03T18:58:01.731184Z","shell.execute_reply":"2024-01-03T18:58:01.730287Z","shell.execute_reply.started":"2024-01-03T18:58:01.722769Z"},"trusted":true},"outputs":[],"source":["df_train_set['Sentiment'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:36:55.162428Z","iopub.status.busy":"2024-02-09T11:36:55.161780Z","iopub.status.idle":"2024-02-09T11:36:55.184773Z","shell.execute_reply":"2024-02-09T11:36:55.183867Z","shell.execute_reply.started":"2024-02-09T11:36:55.162392Z"},"trusted":true},"outputs":[],"source":["le = LabelEncoder()\n","\n","df_train_set['Sentiment'] = le.fit_transform(df_train_set['Sentiment'])\n","df_valid_set['Sentiment'] = le.fit_transform(df_valid_set['Sentiment'])\n","print(df_train_set['Sentiment'].head())\n","print(df_valid_set['Sentiment'].head())"]},{"cell_type":"markdown","metadata":{},"source":["<h4>Function that turn the text of each tweet to lowercase, removes stopwords and special charachters, urls, mentions e.t.c</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:36:55.186247Z","iopub.status.busy":"2024-02-09T11:36:55.185962Z","iopub.status.idle":"2024-02-09T11:36:55.210471Z","shell.execute_reply":"2024-02-09T11:36:55.209590Z","shell.execute_reply.started":"2024-02-09T11:36:55.186223Z"},"trusted":true},"outputs":[],"source":["# NOTE: To remove the stopwords I downloaded locally the stopwords-el.json file from the repository\n","# at https://github.com/stopwords-iso/stopwords-el and uploaded it\n","# to my notebook at gree-stopwords-json-file.\n","\n","# Load Greek stopwords from the JSON file\n","with open('/kaggle/input/stopwords/stopwords_el_2.json', 'r', encoding='utf-8') as file:\n","    greek_stopwords = json.load(file)\n","\n","def preprocess_tweet(tweet):\n","    tweet = tweet.lower().replace('_', ' ')\n","    \n","    # delete mentions\n","    tweet = re.sub(r'@\\w+', '', tweet)\n","    \n","    # delete urls\n","    tweet = re.sub(r'http\\S+', '', tweet)\n","    \n","    # delete special characters but keep the alphanumeric ones, including all Greek letters\n","    #tweet = re.sub(r'[^αβγδεζηθικλμνξοπρστυφχψωςάέίόώύήΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩa-zA-Z0-9\\s]', '', tweet)\n","    \n","    # I keep only greek charachters (I used to keep and english, I am trying it this way to see if I\n","    # will achieve higher f1 score)\n","    tweet = re.sub(r'[^αβγδεζηθικλμνξοπρστυφχψωςάέίόώύήΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩ0-9\\s]', '', tweet)\n","    \n","    # delete Greek stopwords\n","    tweet_words = tweet.split()\n","    cleaned_words = [word for word in tweet_words if word not in greek_stopwords]\n","    tweet = ' '.join(cleaned_words)\n","\n","    tweet = tweet.strip()\n","    \n","    return tweet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:36:55.211807Z","iopub.status.busy":"2024-02-09T11:36:55.211529Z","iopub.status.idle":"2024-02-09T11:37:06.464733Z","shell.execute_reply":"2024-02-09T11:37:06.463886Z","shell.execute_reply.started":"2024-02-09T11:36:55.211774Z"},"trusted":true},"outputs":[],"source":["df_train_set['Text'] = df_train_set['Text'].apply(preprocess_tweet)\n","df_test_set['Text'] = df_test_set['Text'].apply(preprocess_tweet)\n","df_valid_set['Text'] = df_valid_set['Text'].apply(preprocess_tweet)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T18:59:10.618940Z","iopub.status.busy":"2024-01-03T18:59:10.618606Z","iopub.status.idle":"2024-01-03T18:59:10.628540Z","shell.execute_reply":"2024-01-03T18:59:10.627449Z","shell.execute_reply.started":"2024-01-03T18:59:10.618911Z"},"trusted":true},"outputs":[],"source":["print(df_train_set['Text'].head(), '\\n')\n","print(df_test_set['Text'].head(), '\\n')\n","print(df_valid_set['Text'].head(), '\\n')"]},{"cell_type":"markdown","metadata":{},"source":["**We load the spacy model to perform lemmatization tokenaziation for greek words** <br>\n","Sometimes it's necessary to restart the kernel in order for the following to work\n","\n","<h1>ATTENTION:</h1><h2>The following command needs to be executed only one time. If an error occurs from the following spacy.load() command just restart the kernel and run all the commands except this one.</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T19:00:07.096578Z","iopub.status.busy":"2024-01-03T19:00:07.096123Z","iopub.status.idle":"2024-01-03T19:00:22.110675Z","shell.execute_reply":"2024-01-03T19:00:22.108971Z","shell.execute_reply.started":"2024-01-03T19:00:07.096545Z"},"trusted":true},"outputs":[],"source":["%%capture\n","# This needs to be executed only one time. If an error occurs from the following spacy.load() command\n","# just restart the kernel and run all the commands except this one.\n","!pip install -U spacy  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:37:06.466349Z","iopub.status.busy":"2024-02-09T11:37:06.465947Z","iopub.status.idle":"2024-02-09T11:37:13.399331Z","shell.execute_reply":"2024-02-09T11:37:13.398248Z","shell.execute_reply.started":"2024-02-09T11:37:06.466316Z"},"trusted":true},"outputs":[],"source":["nlp = spacy.load('/kaggle/input/el-core-news-lg-4/el_core_news_lg_3/el_core_news_lg-3.7.0')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>LEMMATIZATION - TOKENIZATION</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:37:13.401007Z","iopub.status.busy":"2024-02-09T11:37:13.400642Z","iopub.status.idle":"2024-02-09T11:43:56.626928Z","shell.execute_reply":"2024-02-09T11:43:56.626148Z","shell.execute_reply.started":"2024-02-09T11:37:13.400974Z"},"trusted":true},"outputs":[],"source":["# For the lemmatization tokenazation step, I downloaded locally the el_core_news_lg model,\n","# then I zipped it and I uploaded it as a public dataset.\n","def lemmatize_tokenize_text(text):\n","    doc = nlp(text)\n","    return ' '.join([token.lemma_ for token in doc])\n","\n","\n","df_train_set['Text'] = df_train_set['Text'].apply(lemmatize_tokenize_text)\n","df_test_set['Text'] = df_test_set['Text'].apply(lemmatize_tokenize_text)\n","df_valid_set['Text'] = df_valid_set['Text'].apply(lemmatize_tokenize_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T22:42:44.741289Z","iopub.status.busy":"2024-01-03T22:42:44.740992Z","iopub.status.idle":"2024-01-03T22:42:44.748988Z","shell.execute_reply":"2024-01-03T22:42:44.747860Z","shell.execute_reply.started":"2024-01-03T22:42:44.741264Z"},"trusted":true},"outputs":[],"source":["print(df_train_set['Text'].head(), '\\n')\n","print(df_test_set['Text'].head(), '\\n')\n","print(df_valid_set['Text'].head(), '\\n')"]},{"cell_type":"markdown","metadata":{},"source":["<h1> Number of Unique words - Wordcloud</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T19:09:19.264370Z","iopub.status.busy":"2024-01-03T19:09:19.264026Z","iopub.status.idle":"2024-01-03T19:09:19.276585Z","shell.execute_reply":"2024-01-03T19:09:19.275468Z","shell.execute_reply.started":"2024-01-03T19:09:19.264341Z"},"trusted":true},"outputs":[],"source":["def unique_words_num(tweets):\n","    # Function that counts the number of the unique words from the Text column of each dataframe\n","    words = set() \n","    for tweet in tweets:\n","        words.update(tweet.split())\n","    return len(words)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T19:09:19.282411Z","iopub.status.busy":"2024-01-03T19:09:19.280203Z","iopub.status.idle":"2024-01-03T19:09:19.465015Z","shell.execute_reply":"2024-01-03T19:09:19.463815Z","shell.execute_reply.started":"2024-01-03T19:09:19.282373Z"},"trusted":true},"outputs":[],"source":["print(\"Num of unique words in df_train_set:\", unique_words_num(df_train_set['Text']))\n","print(\"Num of unique words in df_test_set:\", unique_words_num(df_test_set['Text']))\n","print(\"Num of unique words in df_valid_set:\", unique_words_num(df_valid_set['Text']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-03T19:09:19.466884Z","iopub.status.busy":"2024-01-03T19:09:19.466436Z","iopub.status.idle":"2024-01-03T19:09:32.004824Z","shell.execute_reply":"2024-01-03T19:09:32.003944Z","shell.execute_reply.started":"2024-01-03T19:09:19.466850Z"},"trusted":true},"outputs":[],"source":["def plot_wordcloud(tweets, title):\n","    tweets_joined = ' '.join(tweets)\n","    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=200).generate(tweets_joined)\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(wordcloud, interpolation='bilinear')\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.show()\n","\n","# Plot word cloud for each dataframe\n","plot_wordcloud(df_train_set['Text'], 'df_train_set')\n","plot_wordcloud(df_test_set['Text'], 'df_test_set')\n","plot_wordcloud(df_valid_set['Text'], 'df_valid_set')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Word2Vec</h1>\n","<p>Μετατροπή κειμένου σε vector representation με Word2Vec</p>\n","<p>Train Word2Vec model</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:43:56.628462Z","iopub.status.busy":"2024-02-09T11:43:56.628108Z","iopub.status.idle":"2024-02-09T11:44:01.953685Z","shell.execute_reply":"2024-02-09T11:44:01.952851Z","shell.execute_reply.started":"2024-02-09T11:43:56.628431Z"},"trusted":true},"outputs":[],"source":["all_text = pd.concat([df_train_set['Text'], df_test_set['Text'], df_valid_set['Text']])\n","tokenized_text = [text.split() for text in all_text]\n","\n","# training\n","w2v_model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, workers=4)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Let's examine the distribution of the sequence lengths</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T11:15:24.026482Z","iopub.status.busy":"2024-01-04T11:15:24.026187Z","iopub.status.idle":"2024-01-04T11:15:24.755542Z","shell.execute_reply":"2024-01-04T11:15:24.754574Z","shell.execute_reply.started":"2024-01-04T11:15:24.026455Z"},"trusted":true},"outputs":[],"source":["lengths = [len(text.split()) for text in all_text]\n","plt.hist(lengths, bins=range(1, max(lengths)+1))\n","plt.xlabel('Sequence Length')\n","plt.ylabel('Frequency')\n","plt.title('Distribution of Sequence Lengths')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:01.958183Z","iopub.status.busy":"2024-02-09T11:44:01.957552Z","iopub.status.idle":"2024-02-09T11:44:01.963549Z","shell.execute_reply":"2024-02-09T11:44:01.962493Z","shell.execute_reply.started":"2024-02-09T11:44:01.958154Z"},"trusted":true},"outputs":[],"source":["# https://spotintelligence.com/2023/02/15/word2vec-for-text-classification/\n","def vectorize(sentence, w2v_model, max_length):\n","    words = sentence.split()\n","    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv][:max_length]\n","    padded_vecs = np.zeros((max_length, w2v_model.vector_size))\n","\n","    if len(words_vecs) > 0:\n","        padded_vecs[:len(words_vecs)] = words_vecs\n","\n","    return padded_vecs # we return padded sequences\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:01.964988Z","iopub.status.busy":"2024-02-09T11:44:01.964668Z","iopub.status.idle":"2024-02-09T11:44:01.983716Z","shell.execute_reply":"2024-02-09T11:44:01.982831Z","shell.execute_reply.started":"2024-02-09T11:44:01.964962Z"},"trusted":true},"outputs":[],"source":["df_train_set_vectorized = df_train_set\n","df_valid_set_vectorized = df_valid_set\n","df_test_set_vectorized = df_test_set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:01.985144Z","iopub.status.busy":"2024-02-09T11:44:01.984865Z","iopub.status.idle":"2024-02-09T11:44:05.125415Z","shell.execute_reply":"2024-02-09T11:44:05.124632Z","shell.execute_reply.started":"2024-02-09T11:44:01.985098Z"},"trusted":true},"outputs":[],"source":["max_length = 30\n","df_train_set_vectorized['Text'] = df_train_set_vectorized['Text'].apply(lambda x: vectorize(x, w2v_model, max_length))\n","df_test_set_vectorized['Text'] = df_test_set_vectorized['Text'].apply(lambda x: vectorize(x, w2v_model, max_length))\n","df_valid_set_vectorized['Text'] = df_valid_set_vectorized['Text'].apply(lambda x: vectorize(x, w2v_model, max_length))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T07:58:01.826830Z","iopub.status.busy":"2024-01-30T07:58:01.826086Z","iopub.status.idle":"2024-01-30T07:58:01.921854Z","shell.execute_reply":"2024-01-30T07:58:01.920894Z","shell.execute_reply.started":"2024-01-30T07:58:01.826789Z"},"trusted":true},"outputs":[],"source":["df_train_set_vectorized['Text'].head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T11:15:28.039199Z","iopub.status.busy":"2024-01-04T11:15:28.038935Z","iopub.status.idle":"2024-01-04T11:15:28.044620Z","shell.execute_reply":"2024-01-04T11:15:28.043580Z","shell.execute_reply.started":"2024-01-04T11:15:28.039175Z"},"trusted":true},"outputs":[],"source":["w2v_model.vector_size"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Create dataloaders</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:05.127061Z","iopub.status.busy":"2024-02-09T11:44:05.126770Z","iopub.status.idle":"2024-02-09T11:44:05.872224Z","shell.execute_reply":"2024-02-09T11:44:05.871158Z","shell.execute_reply.started":"2024-02-09T11:44:05.127035Z"},"trusted":true},"outputs":[],"source":["# I do the following in order to avoid the following Warning\n","# UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow.\n","# convert list of numpy arrays to a single numpy array\n","X_train_np = np.stack(df_train_set_vectorized['Text'].values)\n","X_valid_np = np.stack(df_valid_set_vectorized['Text'].values)\n","X_test_np = np.stack(df_test_set_vectorized['Text'].values)\n","\n","# convert numpy arrays to torch tensors\n","X_train = torch.tensor(X_train_np, dtype=torch.float)\n","y_train = torch.tensor(df_train_set_vectorized['Sentiment'].values, dtype=torch.long)\n","X_valid = torch.tensor(X_valid_np, dtype=torch.float)\n","y_valid = torch.tensor(df_valid_set_vectorized['Sentiment'].values, dtype=torch.long)\n","X_test = torch.tensor(X_test_np, dtype=torch.float)\n","\n","# (num_samples, sequence_length, embedding_size)\n","print(\"Shape of X_train:\", X_train.shape)\n","print(\"Shape of X_valid:\", X_valid.shape)\n","print(\"Shape of X_test:\", X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:05.873779Z","iopub.status.busy":"2024-02-09T11:44:05.873488Z","iopub.status.idle":"2024-02-09T11:44:05.879758Z","shell.execute_reply":"2024-02-09T11:44:05.878858Z","shell.execute_reply.started":"2024-02-09T11:44:05.873753Z"},"trusted":true},"outputs":[],"source":["train_dataset = TensorDataset(X_train, y_train)\n","valid_dataset = TensorDataset(X_valid, y_valid)\n","test_dataset = TensorDataset(X_test)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Plotting function</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:05.881500Z","iopub.status.busy":"2024-02-09T11:44:05.881233Z","iopub.status.idle":"2024-02-09T11:44:05.892223Z","shell.execute_reply":"2024-02-09T11:44:05.891477Z","shell.execute_reply.started":"2024-02-09T11:44:05.881466Z"},"trusted":true},"outputs":[],"source":["def plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision):\n","    plt.figure(figsize=(18, 6))  # Adjust the figure size as needed\n","\n","    # Plotting training and validation F1 Score\n","    plt.subplot(1, 3, 1)  # First subplot in a 1x3 grid\n","    plt.plot(train_f1, label='Train F1 Score')\n","    plt.plot(valid_f1, label='Validation F1 Score')\n","    plt.title('Training and Validation F1 Score')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('F1 Score')\n","    plt.legend()\n","\n","    # Plotting training and validation Precision Score\n","    plt.subplot(1, 3, 2)  # Second subplot in a 1x3 grid\n","    plt.plot(train_precision, label='Train Precision Score')\n","    plt.plot(valid_precision, label='Validation Precision Score')\n","    plt.title('Training and Validation Precision Scores')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Precision Score')\n","    plt.legend()\n","\n","    # Plotting training and validation Recall Score\n","    plt.subplot(1, 3, 3)  # Third subplot in a 1x3 grid\n","    plt.plot(train_recall, label='Train Recall Score')\n","    plt.plot(valid_recall, label='Validation Recall Score')\n","    plt.title('Training and Validation Recall Score')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Recall Score')\n","    plt.legend()\n","\n","    # Show the plot\n","    plt.tight_layout()  # Adjusts the subplots to fit into the figure area.\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiments with layers</h1>\n","<p>Initially we construct a RNN with LSTM cells</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T09:38:17.559912Z","iopub.status.busy":"2024-02-09T09:38:17.559184Z","iopub.status.idle":"2024-02-09T09:38:17.567724Z","shell.execute_reply":"2024-02-09T09:38:17.566657Z","shell.execute_reply.started":"2024-02-09T09:38:17.559875Z"},"trusted":true},"outputs":[],"source":["class RNNModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(RNNModel, self).__init__()\n","        self.num_layers = num_layers # for forward method\n","        self.hidden_size = hidden_size # for forward method\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        #hidden state - cell state\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))  #(batch_size, seq_length, hidden_size)\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T11:44:05.894783Z","iopub.status.busy":"2024-02-09T11:44:05.894466Z","iopub.status.idle":"2024-02-09T11:44:05.914570Z","shell.execute_reply":"2024-02-09T11:44:05.913741Z","shell.execute_reply.started":"2024-02-09T11:44:05.894752Z"},"trusted":true},"outputs":[],"source":["def train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader):\n","\n","    train_f1, valid_f1 = [], []\n","    train_precision, valid_precision = [], []\n","    train_recall, valid_recall = [], []\n","    \n","    best_valid_f1 = 0\n","    epochs_no_improve = 0\n","    patience = 20\n","    \n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_preds, train_labels = [], []\n","\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_func(outputs, labels.long())\n","            loss.backward()\n","            optimizer.step()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_preds.extend(predicted.cpu().numpy())\n","            train_labels.extend(labels.cpu().numpy())\n","\n","        train_f1.append(f1_score(train_labels, train_preds, average='weighted', zero_division=0))\n","        train_precision.append(precision_score(train_labels, train_preds, average='weighted', zero_division=0))\n","        train_recall.append(recall_score(train_labels, train_preds, average='weighted', zero_division=0))\n","\n","        # Validation phase\n","        model.eval()\n","        valid_loss = 0\n","        valid_preds, valid_labels = [], []\n","        with torch.no_grad():\n","            for inputs, labels in valid_loader:\n","                outputs = model(inputs)\n","                loss = loss_func(outputs, labels.long())\n","                valid_loss += loss.item()\n","                _, predicted = torch.max(outputs.data, 1)\n","                valid_preds.extend(predicted.cpu().numpy())\n","                valid_labels.extend(labels.cpu().numpy())\n","\n","        valid_f1.append(f1_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","        valid_precision.append(precision_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","        valid_recall.append(recall_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","            \n","        print(f'Epoch {epoch+1}/{num_epochs}, '\n","              f'Train F1: {train_f1[-1]:.2f}, Valid F1: {valid_f1[-1]:.2f}, '\n","              f'Train Precision: {train_precision[-1]:.2f}, Valid Precision: {valid_precision[-1]:.2f}, '\n","              f'Train Recall: {train_recall[-1]:.2f}, Valid Recall: {valid_recall[-1]:.2f}')\n","\n","        temp_f1 = round(valid_f1[-1], 2)\n","        if temp_f1 > best_valid_f1:\n","            best_valid_f1 = temp_f1\n","            epochs_no_improve = 0\n","            \n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= patience:\n","            print(f'Early stopping triggered after {epoch + 1} epochs')\n","            break\n","\n","    print(f'MEAN TRAIN F1 SCORE: {np.mean(train_f1):.2f}\\n'\n","          f'MEAN VALIDATION F1 SCORE: {np.mean(valid_f1):.2f}\\n'\n","          f'MEAN TRAIN PRECISION: {np.mean(train_precision):.2f}\\n'\n","          f'MEAN VALIDATION PRECISION: {np.mean(valid_precision):.2f}\\n'\n","          f'MEAN TRAIN RECALL: {np.mean(train_recall):.2f}\\n'\n","          f'MEAN VALIDATION RECALL: {np.mean(valid_recall):.2f}\\n')\n","    return model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T08:03:59.669962Z","iopub.status.busy":"2024-01-29T08:03:59.669593Z","iopub.status.idle":"2024-01-29T08:03:59.676825Z","shell.execute_reply":"2024-01-29T08:03:59.675769Z","shell.execute_reply.started":"2024-01-29T08:03:59.669931Z"},"trusted":true},"outputs":[],"source":["def objective(trial):\n","    # num of layers in [1, 10]\n","    num_layers = trial.suggest_int('num_layers', 1, 10)\n","    num_epochs = 100\n","    # Here we create our model\n","    model = RNNModel(input_size=100, hidden_size=128, num_layers=num_layers, num_classes=3)\n","    \n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    # training\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","    print(f'\\n\\nFOR num_layers={num_layers}\\n\\n')\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","    \n","    \n","    return valid_f1[-1] # return the f1 score of the last epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-04T11:15:28.771897Z","iopub.status.busy":"2024-01-04T11:15:28.771564Z","iopub.status.idle":"2024-01-04T14:16:21.076037Z","shell.execute_reply":"2024-01-04T14:16:21.075189Z","shell.execute_reply.started":"2024-01-04T11:15:28.771854Z"},"trusted":true},"outputs":[],"source":["study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=10)\n","\n","# Get the best number of layers\n","optimal_layers = study.best_params['num_layers']\n","print(f'Optimal Number of Layers: {optimal_layers}')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiments with hidden_size</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T09:57:27.464070Z","iopub.status.busy":"2024-01-29T09:57:27.463669Z","iopub.status.idle":"2024-01-29T09:57:27.477460Z","shell.execute_reply":"2024-01-29T09:57:27.476500Z","shell.execute_reply.started":"2024-01-29T09:57:27.464039Z"},"trusted":true},"outputs":[],"source":["def objective_hidden_size(trial):\n","\n","    hidden_size = trial.suggest_int('hidden_size', 32, 256) # suggest int in range [32, 256]\n","    num_epochs = 100\n","    \n","    model = RNNModel(input_size=100, hidden_size=hidden_size, num_layers=2, num_classes=3)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    print(f'\\n\\nFOR hidden_size={hidden_size}\\n\\n')\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","\n","    # return the f1 score of the last epoch as the metric to optimize\n","    return valid_f1[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-08T09:22:42.624272Z","iopub.status.busy":"2024-01-08T09:22:42.623551Z","iopub.status.idle":"2024-01-08T11:59:14.999748Z","shell.execute_reply":"2024-01-08T11:59:14.998866Z","shell.execute_reply.started":"2024-01-08T09:22:42.624238Z"},"trusted":true},"outputs":[],"source":["study_hidden_size = optuna.create_study(direction='maximize')\n","study_hidden_size.optimize(objective_hidden_size, n_trials=10)\n","\n","optimal_hidden_size = study_hidden_size.best_params['hidden_size']\n","print(f'Optimal Hidden Size: {optimal_hidden_size}')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiments with cell type</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T09:46:39.573538Z","iopub.status.busy":"2024-01-30T09:46:39.573159Z","iopub.status.idle":"2024-01-30T09:46:39.583498Z","shell.execute_reply":"2024-01-30T09:46:39.582656Z","shell.execute_reply.started":"2024-01-30T09:46:39.573507Z"},"trusted":true},"outputs":[],"source":["class RNNModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, cell_type='LSTM'):\n","        super(RNNModel, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.cell_type = cell_type\n","        \n","        if cell_type == 'LSTM':\n","            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        elif cell_type == 'GRU':\n","            self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        else:\n","            raise ValueError(\"Unsupported RNN cell type. Choose 'LSTM' or 'GRU'.\")\n","\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        if self.cell_type == 'LSTM':\n","            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","            out, _ = self.rnn(x, (h0, c0))\n","        elif self.cell_type == 'GRU':\n","            out, _ = self.rnn(x, h0)\n","        out = self.fc(out[:, -1, :])\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T10:17:30.762185Z","iopub.status.busy":"2024-01-29T10:17:30.761182Z","iopub.status.idle":"2024-01-29T10:17:30.770350Z","shell.execute_reply":"2024-01-29T10:17:30.769562Z","shell.execute_reply.started":"2024-01-29T10:17:30.762135Z"},"trusted":true},"outputs":[],"source":["def objective(trial):\n","    hidden_size = 88\n","    num_layers = 2\n","    cell_type = trial.suggest_categorical('cell_type', ['LSTM', 'GRU'])\n","    num_epochs = 100\n","    model = RNNModel(input_size=100, hidden_size=hidden_size, num_layers=num_layers, num_classes=3, cell_type=cell_type)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    \n","    print(f'\\n\\nFOR cell type={cell_type}\\n\\n')\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","\n","\n","    return valid_f1[-1]  # return the f1 score of the last epoch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T10:20:36.099265Z","iopub.status.busy":"2024-01-29T10:20:36.098846Z","iopub.status.idle":"2024-01-29T10:52:58.784981Z","shell.execute_reply":"2024-01-29T10:52:58.784065Z","shell.execute_reply.started":"2024-01-29T10:20:36.099233Z"},"trusted":true},"outputs":[],"source":["study_cell_type = optuna.create_study(direction='maximize')\n","study_cell_type.optimize(objective, n_trials=4)\n","\n","optimal_cell_type = study_cell_type.best_params['cell_type']\n","print(f'Optimal Cell Type: {optimal_cell_type}')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiment with skip connections</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T12:20:21.134981Z","iopub.status.busy":"2024-01-29T12:20:21.134589Z","iopub.status.idle":"2024-01-29T12:20:21.145051Z","shell.execute_reply":"2024-01-29T12:20:21.143934Z","shell.execute_reply.started":"2024-01-29T12:20:21.134948Z"},"trusted":true},"outputs":[],"source":["class RNNModelSkipConns(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, skip_connections):\n","        super(RNNModelSkipConns, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.skip_connections = skip_connections\n","\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        outputs = []\n","        if self.skip_connections:\n","            for i in range(self.num_layers):\n","                x, (h0, c0) = self.lstm(x, (h0, c0))\n","                outputs.append(x)\n","                if self.skip_connections and i > 0:\n","                    x = x + outputs[i - 1]  #\n","\n","            out = self.fc(outputs[-1][:, -1, :])\n","            return out\n","        else:\n","            out, _ = self.lstm(x, (h0, c0))  #(batch_size, seq_length, hidden_size)\n","            out = self.fc(out[:, -1, :])\n","            return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T11:38:22.747722Z","iopub.status.busy":"2024-01-29T11:38:22.746946Z","iopub.status.idle":"2024-01-29T11:38:22.754548Z","shell.execute_reply":"2024-01-29T11:38:22.753567Z","shell.execute_reply.started":"2024-01-29T11:38:22.747690Z"},"trusted":true},"outputs":[],"source":["def objective(trial):\n","    hidden_size = 100\n","    num_layers = 2\n","    skip_conn = trial.suggest_categorical('skip_connections', [True, False])\n","    num_epochs = 100\n","    model = RNNModelSkipConns(input_size=100, hidden_size=hidden_size, num_layers=num_layers, num_classes=3, skip_connections=skip_conn)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    \n","    print(f'\\n\\nFOR skip connection={skip_conn}\\n\\n')\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","\n","\n","    return valid_f1[-1] "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T14:10:01.689216Z","iopub.status.busy":"2024-01-29T14:10:01.687964Z","iopub.status.idle":"2024-01-29T15:15:54.077866Z","shell.execute_reply":"2024-01-29T15:15:54.076294Z","shell.execute_reply.started":"2024-01-29T14:10:01.689169Z"},"trusted":true},"outputs":[],"source":["study_skip_connections = optuna.create_study(direction='maximize')\n","study_skip_connections.optimize(objective, n_trials=4)\n","\n","optimal_skip_connections = study_skip_connections.best_params['skip_connections']\n","print(f'Optimal Skip Connections value: {optimal_skip_connections}')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiments with gradient clipping</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T16:49:07.635943Z","iopub.status.busy":"2024-01-30T16:49:07.635696Z","iopub.status.idle":"2024-01-30T16:49:07.651772Z","shell.execute_reply":"2024-01-30T16:49:07.651032Z","shell.execute_reply.started":"2024-01-30T16:49:07.635920Z"},"trusted":true},"outputs":[],"source":["def train_model_with_clipping(model, loss_func, optimizer, num_epochs, train_loader, valid_loader, clip=None):\n","\n","    train_f1, valid_f1 = [], []\n","    train_precision, valid_precision = [], []\n","    train_recall, valid_recall = [], []\n","    \n","    best_valid_f1 = 0\n","    epochs_no_improve = 0\n","    patience = 20\n","    \n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_preds, train_labels = [], []\n","\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_func(outputs, labels.long())\n","            loss.backward()\n","            if clip is not None:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","            optimizer.step()\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            train_preds.extend(predicted.cpu().numpy())\n","            train_labels.extend(labels.cpu().numpy())\n","\n","        train_f1.append(f1_score(train_labels, train_preds, average='weighted', zero_division=0))\n","        train_precision.append(precision_score(train_labels, train_preds, average='weighted', zero_division=0))\n","        train_recall.append(recall_score(train_labels, train_preds, average='weighted', zero_division=0))\n","\n","        # Validation phase\n","        model.eval()\n","        valid_loss = 0\n","        valid_preds, valid_labels = [], []\n","        with torch.no_grad():\n","            for inputs, labels in valid_loader:\n","                outputs = model(inputs)\n","                loss = loss_func(outputs, labels.long())\n","                valid_loss += loss.item()\n","                _, predicted = torch.max(outputs.data, 1)\n","                valid_preds.extend(predicted.cpu().numpy())\n","                valid_labels.extend(labels.cpu().numpy())\n","\n","        valid_f1.append(f1_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","        valid_precision.append(precision_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","        valid_recall.append(recall_score(valid_labels, valid_preds, average='weighted', zero_division=0))\n","            \n","        print(f'Epoch {epoch+1}/{num_epochs}, '\n","              f'Train F1: {train_f1[-1]:.2f}, Valid F1: {valid_f1[-1]:.2f}, '\n","              f'Train Precision: {train_precision[-1]:.2f}, Valid Precision: {valid_precision[-1]:.2f}, '\n","              f'Train Recall: {train_recall[-1]:.2f}, Valid Recall: {valid_recall[-1]:.2f}')\n","\n","        temp_f1 = round(valid_f1[-1], 2)\n","        if temp_f1 > best_valid_f1:\n","            best_valid_f1 = temp_f1\n","            epochs_no_improve = 0\n","            \n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= patience:\n","            print(f'Early stopping triggered after {epoch + 1} epochs')\n","            break\n","\n","    print(f'MEAN TRAIN F1 SCORE: {np.mean(train_f1):.2f}\\n'\n","          f'MEAN VALIDATION F1 SCORE: {np.mean(valid_f1):.2f}\\n'\n","          f'MEAN TRAIN PRECISION: {np.mean(train_precision):.2f}\\n'\n","          f'MEAN VALIDATION PRECISION: {np.mean(valid_precision):.2f}\\n'\n","          f'MEAN TRAIN RECALL: {np.mean(train_recall):.2f}\\n'\n","          f'MEAN VALIDATION RECALL: {np.mean(valid_recall):.2f}\\n')\n","    \n","\n","    return model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T16:49:07.653174Z","iopub.status.busy":"2024-01-30T16:49:07.652896Z","iopub.status.idle":"2024-01-30T16:49:07.667458Z","shell.execute_reply":"2024-01-30T16:49:07.666737Z","shell.execute_reply.started":"2024-01-30T16:49:07.653142Z"},"trusted":true},"outputs":[],"source":["clip_vals = [round(val, 1) for val in list(np.linspace(0.5,10, 5, endpoint=False))]\n","max_f1_dt = {'Clipping value':[], 'Val f1 score':[]}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-30T16:49:07.669603Z","iopub.status.busy":"2024-01-30T16:49:07.668513Z","iopub.status.idle":"2024-01-30T17:26:28.703509Z","shell.execute_reply":"2024-01-30T17:26:28.702603Z","shell.execute_reply.started":"2024-01-30T16:49:07.669575Z"},"trusted":true},"outputs":[],"source":["clip_vals.append(None)\n","for val in clip_vals:\n","    hidden_size = 88\n","    num_layers = 2\n","    num_epochs = 100\n","    model = RNNModel(input_size=100, hidden_size=hidden_size, num_layers=num_layers, num_classes=3)\n","\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    print(f'\\n\\nFOR clipping value={val}\\n\\n')\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model_with_clipping(model, loss_func, optimizer, num_epochs, train_loader, valid_loader, val)\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","    max_f1_dt['Clipping value'].append(val)\n","    max_f1_dt['Val f1 score'].append(np.mean(valid_f1))\n","max_df = pd.DataFrame.from_dict(max_f1_dt)\n","optimal_clip_value = max_df.loc[max_df['Val f1 score'].idxmax(), 'Clipping value']\n","print(f'The optimal value for gradient clipping is {optimal_clip_value}')"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Experiments with dropout</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:02:52.564091Z","iopub.status.busy":"2024-02-09T12:02:52.563689Z","iopub.status.idle":"2024-02-09T12:02:52.571950Z","shell.execute_reply":"2024-02-09T12:02:52.570996Z","shell.execute_reply.started":"2024-02-09T12:02:52.564057Z"},"trusted":true},"outputs":[],"source":["class RNNModelDropout(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n","        super(RNNModelDropout, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout_rate, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:09:41.907795Z","iopub.status.busy":"2024-02-09T12:09:41.907449Z","iopub.status.idle":"2024-02-09T12:51:30.647822Z","shell.execute_reply":"2024-02-09T12:51:30.646834Z","shell.execute_reply.started":"2024-02-09T12:09:41.907769Z"},"trusted":true},"outputs":[],"source":["dropout_vals = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]  \n","max_f1_dt = {'Dropout value': [], 'Val f1 score': []}\n","num_epochs = 100\n","model_dropout_best = None\n","best_valid_f1 = 0\n","for val in dropout_vals:\n","    print(f'\\n\\nFOR dropout value={val}\\n\\n')\n","    model = RNNModelDropout(input_size=100, hidden_size=88, num_layers=2, num_classes=3, dropout_rate=val)\n","    loss_func = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    model, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","    if np.mean(valid_f1) > np.mean(best_valid_f1):\n","        model_dropout_best = model\n","    plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)\n","    max_f1_dt['Dropout value'].append(val)\n","    max_f1_dt['Val f1 score'].append(np.mean(valid_f1))\n","\n","max_df = pd.DataFrame.from_dict(max_f1_dt)\n","optimal_dropout_value = max_df.loc[max_df['Val f1 score'].idxmax(), 'Dropout value']\n","print(f'The optimal value for dropout is {optimal_dropout_value}')\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Attention</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:53:00.847248Z","iopub.status.busy":"2024-02-09T12:53:00.846528Z","iopub.status.idle":"2024-02-09T12:53:00.853014Z","shell.execute_reply":"2024-02-09T12:53:00.852162Z","shell.execute_reply.started":"2024-02-09T12:53:00.847216Z"},"trusted":true},"outputs":[],"source":["class Attention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(Attention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.attn = nn.Linear(self.hidden_size, 1)\n","\n","    def forward(self, outputs):\n","        attn_weights = nn.functional.softmax(self.attn(outputs), dim=1)\n","        context = torch.sum(attn_weights * outputs, dim=1)\n","        return context, attn_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:53:01.224939Z","iopub.status.busy":"2024-02-09T12:53:01.224608Z","iopub.status.idle":"2024-02-09T12:53:01.232684Z","shell.execute_reply":"2024-02-09T12:53:01.231758Z","shell.execute_reply.started":"2024-02-09T12:53:01.224910Z"},"trusted":true},"outputs":[],"source":["class RNNModelAttention(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n","        super(RNNModelAttention, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout_rate, batch_first=True)\n","        self.attention = Attention(hidden_size)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        outputs, _ = self.lstm(x, (h0, c0))\n","        context, attn_weights = self.attention(outputs)\n","        out = self.fc(context)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T13:12:27.093993Z","iopub.status.busy":"2024-02-09T13:12:27.093314Z","iopub.status.idle":"2024-02-09T13:17:41.912015Z","shell.execute_reply":"2024-02-09T13:17:41.911069Z","shell.execute_reply.started":"2024-02-09T13:12:27.093961Z"},"trusted":true},"outputs":[],"source":["num_epochs = 100\n","model = RNNModelAttention(100, 88, 2, 3, 0.1)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","model_attention, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Enhanced attention</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T12:59:33.047584Z","iopub.status.busy":"2024-02-09T12:59:33.046605Z","iopub.status.idle":"2024-02-09T12:59:33.054907Z","shell.execute_reply":"2024-02-09T12:59:33.053840Z","shell.execute_reply.started":"2024-02-09T12:59:33.047543Z"},"trusted":true},"outputs":[],"source":["class EnhancedAttention(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(EnhancedAttention, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.query = nn.Parameter(torch.randn(hidden_size), requires_grad=True)  \n","        self.attn = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, lstm_outputs):\n","        transformed_outputs = self.attn(lstm_outputs)  # (batch_size, seq_len, hidden_size)\n","        scores = torch.matmul(transformed_outputs, self.query)  # (batch_size, seq_len)\n","        attn_weights = self.softmax(scores)  # (batch_size, seq_len)\n","        context = torch.sum(lstm_outputs * attn_weights.unsqueeze(2), dim=1)\n","        return context, attn_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T13:01:21.441220Z","iopub.status.busy":"2024-02-09T13:01:21.440830Z","iopub.status.idle":"2024-02-09T13:01:21.449674Z","shell.execute_reply":"2024-02-09T13:01:21.448697Z","shell.execute_reply.started":"2024-02-09T13:01:21.441187Z"},"trusted":true},"outputs":[],"source":["class RNNModelWithEnhancedAttention(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.0):\n","        super(RNNModelWithEnhancedAttention, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout_rate, batch_first=True)\n","        self.attention = EnhancedAttention(hidden_size)\n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n","        lstm_outputs, _ = self.lstm(x, (h0, c0))\n","        context, attn_weights = self.attention(lstm_outputs)\n","        out = self.fc(context)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T13:17:41.914223Z","iopub.status.busy":"2024-02-09T13:17:41.913888Z","iopub.status.idle":"2024-02-09T13:22:21.561625Z","shell.execute_reply":"2024-02-09T13:22:21.560658Z","shell.execute_reply.started":"2024-02-09T13:17:41.914195Z"},"trusted":true},"outputs":[],"source":["num_epochs = 100\n","model = RNNModelWithEnhancedAttention(100, 88, 2, 3, 0.1)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","model_attention_enchanced, train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision = train_model(model, loss_func, optimizer, num_epochs, train_loader, valid_loader)\n","plot_f1_recall_precision(train_f1, valid_f1, train_recall, valid_recall, train_precision, valid_precision)"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Predictions</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T13:27:17.201012Z","iopub.status.busy":"2024-02-09T13:27:17.200630Z","iopub.status.idle":"2024-02-09T13:27:18.159465Z","shell.execute_reply":"2024-02-09T13:27:18.158407Z","shell.execute_reply.started":"2024-02-09T13:27:17.200982Z"},"trusted":true},"outputs":[],"source":["model_attention_enchanced.eval() # We use the second attention model\n","\n","with torch.no_grad():\n","    test_preds = []\n","    for inputs in test_loader:\n","        inputs = inputs[0]\n","        outputs = model_attention_enchanced(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_preds.extend(predicted.cpu().numpy())\n","\n","predicted_labels = le.inverse_transform(test_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-09T13:27:19.190013Z","iopub.status.busy":"2024-02-09T13:27:19.189660Z","iopub.status.idle":"2024-02-09T13:27:19.231845Z","shell.execute_reply":"2024-02-09T13:27:19.230914Z","shell.execute_reply.started":"2024-02-09T13:27:19.189983Z"},"trusted":true},"outputs":[],"source":["results = pd.DataFrame({\n","    'Id': df_test_set['New_ID'],\n","    'Predicted': predicted_labels\n","})\n","\n","results.to_csv('submission.csv', index=False)\n","results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7351814,"sourceId":66593,"sourceType":"competition"},{"datasetId":4256706,"sourceId":7332643,"sourceType":"datasetVersion"},{"datasetId":4256734,"sourceId":7332689,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
